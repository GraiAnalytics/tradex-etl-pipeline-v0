````markdown
# TradeX â€“ Data Pipeline ETL

Pipeline ETL **profesional y escalable** para **TradeX**, orientado a la ingestiÃ³n, normalizaciÃ³n y generaciÃ³n de **seÃ±ales accionables para el mercado financiero** a partir de:

- datos alternativos (X/Twitter, Reddit, YouTube, News/RSS, SEC, arXiv, journals)
- datos de mercado (Alpaca)

El pipeline estÃ¡ diseÃ±ado bajo una arquitectura **Bronze / Silver / Gold**, con foco en:

- reproducibilidad
- auditorÃ­a
- escalabilidad
- observabilidad
- data quality
- backfills seguros
- idempotencia (re-ejecuciones sin duplicar)

---

## ğŸ“ Arquitectura de alto nivel

```text
FUENTES EXTERNAS
(X, Reddit, YouTube, RSS, SEC, arXiv, Alpaca)
        |
        v
      BRONZE
   (raw / immutable)
        |
        v
      SILVER
 (clean / canonical)
        |
        v
       GOLD
 (metrics / signals)
        |
        v
 UI / API / ALERTS / ML
````

* **Bronze**: datos crudos, auditables y append-only (`JSONL.gz`, run_id + manifest + `_SUCCESS`)
* **Silver**: datos limpios y canÃ³nicos (`Parquet/Iceberg`, entity-resolved)
* **Gold**: data products y seÃ±ales explicables, listos para serving

La especificaciÃ³n completa de cada capa estÃ¡ en `/docs/architecture`.

---

## ğŸ¯ Objetivos del pipeline

* Ingestar mÃºltiples fuentes heterogÃ©neas sin perder informaciÃ³n (**raw payload preservado en Bronze**)
* Normalizar y resolver entidades de forma consistente (`entity_id`)
* Calcular mÃ©tricas relativas (baselines, deltas, z-scores)
* Detectar seÃ±ales explicables (spikes, anomalÃ­as, divergencias)
* Servir datos listos para UI, alertas y modelos ML
* Permitir reprocesamiento y auditorÃ­a completa (**run_id + manifest + state store**)
* Soportar incremental y backfills con la misma lÃ³gica (sin hacks)

---

## ğŸ§± Capas de datos

### ğŸŸ¤ Bronze (Raw / Ingest)

Bronze es un **log de ingestas inmutable** con commit atÃ³mico por `run_id`.

* Copia fiel de las fuentes externas (con envelope estÃ¡ndar)
* Versionado y auditabilidad total
* Metadata tÃ©cnica (`ingest_time`, `event_time`, `cursor`, `params`)
* Manifiesto por corrida (`manifest.json`) y marcador `_SUCCESS`
* DeduplicaciÃ³n in-run + persistente (Postgres)

Ejemplos de datasets:

* `x.posts`
* `market.daily_prices`
* `reddit.posts`
* `youtube.comments`
* `sec.filings`

ğŸ“„ EspecificaciÃ³n: `docs/architecture/01_bronze.md`

---

### âšª Silver (Clean / Canonical)

Silver define la **verdad estructural** del sistema.

* Datos limpios, tipados y normalizados
* ResoluciÃ³n determinÃ­stica de entidades (`entity_id`)
* DeduplicaciÃ³n semÃ¡ntica
* Manejo de late data y schema drift
* Base confiable para anÃ¡lisis, features y seÃ±ales

Tablas canÃ³nicas:

* `silver_entity_master`
* `silver_social_events`
* `silver_market_daily`

ğŸ“„ EspecificaciÃ³n: `docs/architecture/02_silver.md`

---

### ğŸŸ¡ Gold (Business / Signals)

Gold es la capa de **productos de datos**.

* MÃ©tricas finales (market + social)
* Baselines y features versionadas
* SeÃ±ales explicables con drivers y confidence
* Tablas optimizadas para UI, feeds y alertas

Ejemplos:

* `gold_market_entity_day`
* `gold_social_entity_day`
* `gold_baselines_entity_day`
* `gold_signal_events`
* `gold_entity_daily_summary`

ğŸ“„ EspecificaciÃ³n: `docs/architecture/03_gold.md`

---

## ğŸ§© Datasets soportados (v0)

### Social / Alt-data

* **X (Twitter) â€“ Basic (API v2)**
  `x.posts` (recent search con cursor `start_time` + lookback + dedup)
* `reddit.posts`
* `youtube.comments`
* `news.articles_rss`
* `journals.articles_rss`
* `sec.filings`
* `arxiv.papers`

### Market

* **Alpaca**
  `market.daily_prices`

---

## ğŸ› ï¸ Stack tecnolÃ³gico

* **Lenguaje**: Python 3.11+
* **OrquestaciÃ³n**: Dagster (Python-first)
* **Storage**: S3-compatible (MinIO dev / S3 prod)
* **Formato**:

  * Bronze: JSONL.gz
  * Silver / Gold: Parquet + Iceberg (o Delta)
* **Estado / Metadata**: Postgres
* **Data Quality**: contracts + quality gates + quarantine
* **Observabilidad**: logs estructurados + mÃ©tricas por run

---

## ğŸ“ Estructura del repositorio (resumen)

```text
src/tradex_pipeline/
â”œâ”€ sources/        # extractores por fuente
â”œâ”€ bronze/         # runner + envelopes + manifests + dedup
â”œâ”€ silver/         # parsers + transforms + quality
â”œâ”€ gold/           # metrics + baselines + signals + serving
â”œâ”€ contracts/      # definiciÃ³n formal de datasets
â”œâ”€ state/          # cursores, watermarks, dedup (Postgres)
â”œâ”€ orchestration/  # dagster jobs / schedules
â”œâ”€ alerts/         # dispatch de alertas
â””â”€ common/         # utilidades compartidas
```

---

## ğŸš€ Quickstart (local)

### 1ï¸âƒ£ Requisitos

* Python 3.11+
* Docker + Docker Compose
* Poetry
* Make (opcional)

---

### 2ï¸âƒ£ Clonar el repositorio

```bash
git clone git@github.com:tradex-ai/tradex-pipeline-etl.git
cd tradex-pipeline-etl
```

---

### 3ï¸âƒ£ Variables de entorno

```bash
cp .env.example .env
```

Configura al menos:

* X API v2 (Basic)
* Alpaca Market Data
* Storage (MinIO/S3)
* Postgres

---

### 4ï¸âƒ£ Levantar stack local

```bash
docker-compose up -d
```

Servicios:

* MinIO
* Postgres
* dependencias del pipeline

---

### 5ï¸âƒ£ Instalar dependencias

```bash
poetry install
poetry shell
```

---

## â–¶ï¸ EjecuciÃ³n de pipelines

> Los datasets se ejecutan con `dataset_key = source.dataset`.

### Bronze

```bash
python -m tradex_pipeline.cli run bronze x.posts
python -m tradex_pipeline.cli run bronze market.daily_prices
```

### Silver

```bash
python -m tradex_pipeline.cli run silver social_events
python -m tradex_pipeline.cli run silver market_daily
```

### Gold

```bash
python -m tradex_pipeline.cli run gold build_metrics
python -m tradex_pipeline.cli run gold detect_signals
python -m tradex_pipeline.cli run gold build_serving
```

---

## ğŸ” Backfills

Ejemplo: backfill temporal de X posts

```bash
python -m tradex_pipeline.cli backfill \
  --layer bronze \
  --dataset x.posts \
  --start-date 2025-12-01 \
  --end-date 2025-12-15
```

Reglas:

* Bronze genera nuevos `run_id`
* Dedup evita duplicados
* Silver y Gold se recalculan desde Bronze

---

## ğŸ§ª Data Quality

* Contracts por dataset (`contracts/`)
* Quality gates en Silver y Gold
* Registros invÃ¡lidos â†’ quarantine
* Fallos crÃ­ticos bloquean publicaciÃ³n

---

## ğŸ“Š Observabilidad

Por cada `run_id` se mide:

* volumen de datos
* latencia por etapa
* errores por tipo
* lag temporal
* drift de esquema

Alertas automÃ¡ticas ante:

* fallos consecutivos
* anomalÃ­as de volumen
* pÃ©rdida de frescura

ğŸ“„ Detalle: `docs/architecture/06_observability.md`

---

## ğŸ” Seguridad

* Secrets vÃ­a `.env` o secret manager
* Storage cifrado
* Acceso por roles a Bronze / Silver / Gold
* RetenciÃ³n configurable por capa

---

## ğŸ§  FilosofÃ­a de diseÃ±o

* **Bronze nunca se modifica**
* **Silver es la verdad canÃ³nica**
* **Gold es un data product**
* Todo es:

  * versionado
  * reproducible
  * explicable
  * auditable
* Agregar una nueva fuente = extractor + config + contract

---

## ğŸ“Œ PrÃ³ximos pasos

1. Revisar `/docs/architecture`
2. Completar `configs/base.yaml`
3. Ejecutar los primeros datasets Bronze
4. Publicar las primeras tablas Silver
5. Activar seÃ±ales Gold

---

## ğŸ“¬ Proyecto

**TradeX** es una plataforma enfocada en **seÃ±ales de mercado basadas en datos alternativos**, combinando ingenierÃ­a de datos, modelos financieros/estadÃ­sticos, ML/DL y una capa agÃ©ntica de IA para alertas rÃ¡pidas.

```